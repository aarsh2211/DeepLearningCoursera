{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIGNS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9m5qdM5Ktu6",
        "colab_type": "code",
        "outputId": "ab57d84e-bc50-4a8b-cddb-fa95d622aa62",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 41
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da7bd6f0-204c-46d9-ba60-7d36b7c2b709\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-da7bd6f0-204c-46d9-ba60-7d36b7c2b709\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0iGRg70KuVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nznFwhGEL5f3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = h5py.File(\"train_signs.h5\", 'r+')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPVk7akguI-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7PTmYWmmdcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
        "    mini_batch_size -- size of the mini-batches, integer\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    n = Y.shape[1]    \n",
        " \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    permutationy = list(np.random.permutation(6))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:,permutationy].reshape((1,m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        ### START CODE HERE ### (approx. 2 lines)\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : (k + 1) * mini_batch_size]\n",
        "        ### END CODE HERE ###\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        ### START CODE HERE ### (approx. 2 lines)\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size:]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size:]\n",
        "        ### END CODE HERE ###\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9i89SBKMFs9",
        "colab_type": "code",
        "outputId": "eaf7b387-5b7d-4e32-ee74-cbdb0b31a370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<HDF5 file \"train_signs.h5\" (mode r+)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg894Fb0MINz",
        "colab_type": "code",
        "outputId": "33655c96-7aee-41fc-bf5f-94c5f34a95aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "list(dataset.keys())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['list_classes', 'train_set_x', 'train_set_y']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlyKMj7hMVCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_x = np.array(dataset[\"train_set_x\"][:]) # your train set features\n",
        "train_data_y = np.array(dataset[\"train_set_y\"][:]) # your train set labels\n",
        "train_data_classes = dataset['list_classes']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUH-MUdoMrt9",
        "colab_type": "code",
        "outputId": "b99f880c-8843-4cef-db8b-b49eec9c486b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "print(train_data_y[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wONFGta3M24n",
        "colab_type": "code",
        "outputId": "5e9d16d0-3fd0-4fbe-d622-fcb2f8772b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(train_data_x.shape)\n",
        "print(train_data_y.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 64, 64, 3)\n",
            "(1080,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiiuYGhDNu9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.divide(train_data_x,255)\n",
        "y_train = convert_to_one_hot(train_data_y, 6).T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvFXhxWBOGCc",
        "colab_type": "code",
        "outputId": "7a932303-9486-41ff-ad50-fa096e3fbc83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1673
        }
      },
      "source": [
        "print(train_data_x[1])\n",
        "print(\"   \")\n",
        "print(x_train[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[238 232 223]\n",
            "  [238 232 223]\n",
            "  [238 232 223]\n",
            "  ...\n",
            "  [222 216 209]\n",
            "  [221 216 207]\n",
            "  [221 216 206]]\n",
            "\n",
            " [[237 232 223]\n",
            "  [238 232 223]\n",
            "  [238 232 223]\n",
            "  ...\n",
            "  [222 216 209]\n",
            "  [222 216 208]\n",
            "  [223 217 207]]\n",
            "\n",
            " [[236 232 222]\n",
            "  [237 232 223]\n",
            "  [238 232 223]\n",
            "  ...\n",
            "  [222 216 209]\n",
            "  [222 216 208]\n",
            "  [221 216 207]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[218 212 204]\n",
            "  [217 212 204]\n",
            "  [217 211 205]\n",
            "  ...\n",
            "  [214 203 194]\n",
            "  [214 203 195]\n",
            "  [214 204 194]]\n",
            "\n",
            " [[217 211 203]\n",
            "  [217 211 203]\n",
            "  [216 210 203]\n",
            "  ...\n",
            "  [214 203 194]\n",
            "  [215 203 194]\n",
            "  [215 204 193]]\n",
            "\n",
            " [[216 210 202]\n",
            "  [216 210 203]\n",
            "  [215 209 203]\n",
            "  ...\n",
            "  [214 203 194]\n",
            "  [215 203 194]\n",
            "  [215 204 192]]]\n",
            "   \n",
            "[[[0.93333333 0.90980392 0.8745098 ]\n",
            "  [0.93333333 0.90980392 0.8745098 ]\n",
            "  [0.93333333 0.90980392 0.8745098 ]\n",
            "  ...\n",
            "  [0.87058824 0.84705882 0.81960784]\n",
            "  [0.86666667 0.84705882 0.81176471]\n",
            "  [0.86666667 0.84705882 0.80784314]]\n",
            "\n",
            " [[0.92941176 0.90980392 0.8745098 ]\n",
            "  [0.93333333 0.90980392 0.8745098 ]\n",
            "  [0.93333333 0.90980392 0.8745098 ]\n",
            "  ...\n",
            "  [0.87058824 0.84705882 0.81960784]\n",
            "  [0.87058824 0.84705882 0.81568627]\n",
            "  [0.8745098  0.85098039 0.81176471]]\n",
            "\n",
            " [[0.9254902  0.90980392 0.87058824]\n",
            "  [0.92941176 0.90980392 0.8745098 ]\n",
            "  [0.93333333 0.90980392 0.8745098 ]\n",
            "  ...\n",
            "  [0.87058824 0.84705882 0.81960784]\n",
            "  [0.87058824 0.84705882 0.81568627]\n",
            "  [0.86666667 0.84705882 0.81176471]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.85490196 0.83137255 0.8       ]\n",
            "  [0.85098039 0.83137255 0.8       ]\n",
            "  [0.85098039 0.82745098 0.80392157]\n",
            "  ...\n",
            "  [0.83921569 0.79607843 0.76078431]\n",
            "  [0.83921569 0.79607843 0.76470588]\n",
            "  [0.83921569 0.8        0.76078431]]\n",
            "\n",
            " [[0.85098039 0.82745098 0.79607843]\n",
            "  [0.85098039 0.82745098 0.79607843]\n",
            "  [0.84705882 0.82352941 0.79607843]\n",
            "  ...\n",
            "  [0.83921569 0.79607843 0.76078431]\n",
            "  [0.84313725 0.79607843 0.76078431]\n",
            "  [0.84313725 0.8        0.75686275]]\n",
            "\n",
            " [[0.84705882 0.82352941 0.79215686]\n",
            "  [0.84705882 0.82352941 0.79607843]\n",
            "  [0.84313725 0.81960784 0.79607843]\n",
            "  ...\n",
            "  [0.83921569 0.79607843 0.76078431]\n",
            "  [0.84313725 0.79607843 0.76078431]\n",
            "  [0.84313725 0.8        0.75294118]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsvPFRwYP94n",
        "colab_type": "code",
        "outputId": "9286f2d0-e226-46df-b463-3a8c63f4d9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ApqmH9wIjb",
        "colab_type": "code",
        "outputId": "daf20398-7367-4409-ae19-2fec1c159446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(y_train.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np8vsVdHwK5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_placeholder(h,w,c,y):\n",
        "  X = tf.placeholder(tf.float32, shape=[1080,h,w,c])\n",
        "  Y = tf.placeholder(tf.float32,shape=[1080,y])\n",
        "  return X,Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifZxVhVlAmmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y = make_placeholder(64,64,3,6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eDOBPlNAxDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "45053f9d-0876-4f7d-e1d0-145cd22c5d5d"
      },
      "source": [
        "print (str(X)+\"  \"+ str(Y))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(1080, 64, 64, 3), dtype=float32)  Tensor(\"Placeholder_1:0\", shape=(1080, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y8mdDVXA3Y8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "  tf.set_random_seed(1)\n",
        "  W1 = tf.get_variable('W1', [4,4,3,8], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
        "  W2 = tf.get_variable('W2', [2,2,8,16], initializer = tf.contrib.layers.xavier_initializer(seed=0))\n",
        "  parameters= {\"W1\":W1,\n",
        "               \"W2\": W2\n",
        "      \n",
        "  }\n",
        "  return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74cMH6mNLMWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e1695bd8-baff-47ae-dbfc-3fdd3ea284e5"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as tf_sess:\n",
        "  parameters = initialize_parameters()\n",
        "  init = tf.global_variables_initializer()\n",
        "  tf_sess.run(init)\n",
        "  print(\"W1 = \" + str(parameters[\"W1\"].eval()[1,1,1,1]))\n",
        "  print(\"W2 = \" + str(parameters[\"W2\"].eval()[1,1,1,1]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "W1 = 0.1417614\n",
            "W2 = 0.17750949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wqd1tARM3Me",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4132
        },
        "outputId": "44f909ef-d4b0-42ff-db4b-319da90d0919"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess_test:\n",
        "    parameters = initialize_parameters()\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess_test.run(init)\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"].eval()))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"].eval()))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1 = [[[[ 0.11547081 -0.15562162  0.14463945 -0.12213563 -0.161331\n",
            "     0.0167321   0.00137798  0.15687598]\n",
            "   [ 0.06261188  0.15809353 -0.13944083  0.1304368   0.14947264\n",
            "     0.07770665 -0.0344099   0.02789916]\n",
            "   [ 0.1310067   0.03547595  0.1019934   0.17467071 -0.16157703\n",
            "    -0.06069881 -0.10278072 -0.06633689]]\n",
            "\n",
            "  [[-0.1701455  -0.15981087 -0.06383926 -0.00349012 -0.14234345\n",
            "    -0.05761932  0.00821769 -0.07173218]\n",
            "   [ 0.14097519  0.11141728  0.18437327  0.0588678  -0.13764857\n",
            "    -0.11404216  0.05882488  0.09655331]\n",
            "   [ 0.09364428 -0.03100704  0.16560768  0.14417745  0.15409656\n",
            "    -0.08602516 -0.12028332 -0.16772161]]\n",
            "\n",
            "  [[ 0.18019755 -0.17030357 -0.10018802 -0.18330556  0.03716455\n",
            "    -0.09169444 -0.01606575 -0.10697315]\n",
            "   [-0.1352132   0.04067522  0.07451691  0.02565144 -0.08935398\n",
            "    -0.14955646  0.17125843 -0.10636543]\n",
            "   [ 0.1641133  -0.16645104  0.14331098 -0.0984499  -0.02071032\n",
            "    -0.13608913  0.15722917 -0.05736801]]\n",
            "\n",
            "  [[ 0.18048044  0.12755601  0.09927674 -0.07896702 -0.01106757\n",
            "     0.12510462  0.10254164 -0.0530639 ]\n",
            "   [ 0.09258421 -0.04108836 -0.05156758 -0.18287908 -0.1201285\n",
            "     0.18191533 -0.09046397 -0.06246264]\n",
            "   [ 0.0652394  -0.15792422 -0.1635998   0.17045619 -0.01177415\n",
            "     0.05414602  0.16976361  0.1313066 ]]]\n",
            "\n",
            "\n",
            " [[[-0.1276688  -0.0151097   0.09537239 -0.09044442  0.1176459\n",
            "    -0.08076607  0.1509314   0.06640787]\n",
            "   [ 0.03119117  0.11769979  0.1076581  -0.01755811 -0.12652452\n",
            "    -0.08751073  0.0767848  -0.08363672]\n",
            "   [-0.07881     0.12069152  0.05915618 -0.10101575 -0.01375258\n",
            "     0.09362705 -0.02805306 -0.09040824]]\n",
            "\n",
            "  [[ 0.16443549 -0.09292883  0.05716194  0.08276136  0.11203139\n",
            "     0.06421891 -0.00729965  0.13727976]\n",
            "   [ 0.00131723  0.1417614  -0.04434952  0.09197326  0.14984085\n",
            "    -0.03514394 -0.06847463  0.05245192]\n",
            "   [ 0.17308395 -0.07463694 -0.1627092   0.15460996 -0.08179158\n",
            "    -0.13378257  0.00564247  0.16062535]]\n",
            "\n",
            "  [[ 0.13059764 -0.00192186 -0.11307718 -0.18133381 -0.05553304\n",
            "     0.02143283 -0.11456852  0.0528446 ]\n",
            "   [-0.09188157 -0.00452077 -0.01033492 -0.087416   -0.01735702\n",
            "     0.02977444  0.00052984  0.00983675]\n",
            "   [-0.15542524 -0.01869164  0.03142871 -0.05312751  0.16560926\n",
            "    -0.09097554  0.08132382 -0.14448032]]\n",
            "\n",
            "  [[ 0.08929332 -0.17300954 -0.0014689  -0.17412269 -0.01236047\n",
            "     0.0417559   0.04234362  0.02787495]\n",
            "   [ 0.14712255 -0.16533229 -0.12082531  0.05418657 -0.01176724\n",
            "     0.01966397 -0.11076181  0.05106527]\n",
            "   [ 0.08188905 -0.10437318 -0.03012811  0.11816578 -0.1605425\n",
            "     0.1754932   0.14070319 -0.12122801]]]\n",
            "\n",
            "\n",
            " [[[-0.10985722  0.00432044  0.00896505 -0.0881089  -0.08848276\n",
            "     0.00863551  0.15536223  0.05154584]\n",
            "   [-0.05037339  0.09931098 -0.17829435  0.01767568 -0.08340865\n",
            "    -0.06263054  0.01612224  0.16876729]\n",
            "   [-0.1194736   0.11054228 -0.11331978  0.09310131 -0.10664946\n",
            "     0.13256015 -0.06946554 -0.11520903]]\n",
            "\n",
            "  [[ 0.16194074 -0.14686722 -0.12353867 -0.15883712  0.06531674\n",
            "     0.01186568 -0.08830131 -0.1453381 ]\n",
            "   [-0.11682992  0.1258529  -0.16491483  0.11780094 -0.06159177\n",
            "    -0.09904815 -0.16852126  0.07559638]\n",
            "   [-0.1770666   0.03841008  0.06194262  0.13051493 -0.04662523\n",
            "     0.10323875  0.04866305  0.09327753]]\n",
            "\n",
            "  [[-0.08677699  0.13345896  0.14411353  0.07402633  0.17853673\n",
            "    -0.17118461  0.13299449  0.04484366]\n",
            "   [-0.0477975   0.03531374  0.00538918  0.05524488  0.13791884\n",
            "     0.05704719  0.10665409  0.01218429]\n",
            "   [-0.02445702  0.09296604 -0.02939983 -0.07282878 -0.09431875\n",
            "     0.07386138  0.08730365 -0.13300917]]\n",
            "\n",
            "  [[-0.11411674 -0.12772955  0.12570257 -0.0296371  -0.14701442\n",
            "     0.1293747   0.07933183  0.01307277]\n",
            "   [ 0.05453169  0.03466724  0.15829597  0.14806415  0.13052414\n",
            "     0.18101163  0.1082833   0.14259486]\n",
            "   [-0.09484331 -0.09866115  0.10171987 -0.09913518  0.04908362\n",
            "    -0.11938292  0.13852538  0.06013463]]]\n",
            "\n",
            "\n",
            " [[[ 0.04723395  0.12427522  0.13143836  0.01017329 -0.06754398\n",
            "     0.07398213  0.09188254 -0.04818894]\n",
            "   [ 0.12729175 -0.04897885 -0.08968189  0.10791881 -0.03634022\n",
            "     0.01406936  0.06535503  0.06877695]\n",
            "   [-0.15827248  0.11055781  0.09597807 -0.0635449  -0.11517187\n",
            "    -0.14547585 -0.03765407  0.11134703]]\n",
            "\n",
            "  [[-0.15231502  0.14108427 -0.04393423  0.1197993   0.04059035\n",
            "    -0.12795182  0.05467723  0.17338474]\n",
            "   [ 0.13689046 -0.01458083  0.10258235 -0.00747211 -0.17994192\n",
            "    -0.15795825 -0.1545277  -0.05960114]\n",
            "   [-0.01873805 -0.0986744  -0.03393377 -0.13624606  0.07541598\n",
            "    -0.00854653 -0.0889894  -0.02335989]]\n",
            "\n",
            "  [[ 0.11911012 -0.18236025  0.03056322 -0.16970247 -0.09283181\n",
            "     0.01669209  0.12650074 -0.12198777]\n",
            "   [ 0.04790117 -0.12337236  0.17987971 -0.13652207  0.1565762\n",
            "    -0.14924584 -0.00282751  0.08280452]\n",
            "   [-0.04915185  0.13603546  0.07698585 -0.13521378 -0.14091624\n",
            "    -0.18266377 -0.16046709 -0.11843611]]\n",
            "\n",
            "  [[-0.0050036  -0.11442259  0.0118302  -0.06936064  0.1735499\n",
            "    -0.07373526  0.17584409 -0.06918319]\n",
            "   [ 0.16454048 -0.1698395  -0.0988445   0.01970342  0.1596723\n",
            "    -0.07270284  0.03040822  0.02601132]\n",
            "   [-0.00218067 -0.04939128 -0.11902361 -0.1844188  -0.16679502\n",
            "     0.03561163 -0.01817229 -0.17090265]]]]\n",
            "W2 = [[[[ 0.15634823 -0.21071267  0.19584274 -0.16537243 -0.21844321\n",
            "     0.02265537  0.0018658   0.2124111   0.08477688  0.21405965\n",
            "    -0.18880379  0.17661226  0.20238692  0.10521531 -0.04659122\n",
            "     0.03777564]\n",
            "   [ 0.1773839   0.04803467  0.13809973  0.23650527 -0.21877635\n",
            "    -0.08218658 -0.13916576 -0.08982056 -0.23037809 -0.21638495\n",
            "    -0.08643878 -0.00472564 -0.19273394 -0.07801694  0.01112682\n",
            "    -0.09712583]\n",
            "   [ 0.19088131  0.15085971  0.24964261  0.07970738 -0.18637705\n",
            "    -0.15441382  0.07964927  0.13073379  0.12679493 -0.04198372\n",
            "     0.22423387  0.19521719  0.20864773 -0.11647862 -0.16286439\n",
            "    -0.22709614]\n",
            "   [ 0.24398863 -0.23059213 -0.13565522 -0.2481969   0.05032104\n",
            "    -0.12415487 -0.02175313 -0.14484233 -0.18307954  0.05507451\n",
            "     0.10089636  0.03473222 -0.12098587 -0.2025004   0.23188502\n",
            "    -0.14401948]\n",
            "   [ 0.22221047 -0.22537577  0.194044   -0.1333018  -0.0280419\n",
            "    -0.18426555  0.21288931 -0.07767665  0.24437165  0.17271167\n",
            "     0.13442135 -0.10692185 -0.01498556  0.16939247  0.13884205\n",
            "    -0.07184887]\n",
            "   [ 0.1253596  -0.0556339  -0.06982285 -0.24761945 -0.16265476\n",
            "     0.24631453 -0.1224888  -0.08457482  0.08833456 -0.21383041\n",
            "    -0.22151518  0.23079878 -0.01594228  0.07331407  0.22986102\n",
            "     0.17778999]\n",
            "   [-0.17286438 -0.02045864  0.12913483 -0.12246233  0.1592933\n",
            "    -0.10935777  0.2043621   0.08991671  0.04223305  0.15936625\n",
            "     0.14576977 -0.02377379 -0.17131501 -0.1184901   0.10396713\n",
            "    -0.11324465]\n",
            "   [-0.10670924  0.1634171   0.08009785 -0.13677597 -0.01862109\n",
            "     0.12677163 -0.03798401 -0.12241334  0.22264671 -0.12582624\n",
            "     0.07739764  0.11205941  0.1516912   0.08695281 -0.00988376\n",
            "     0.18587768]]\n",
            "\n",
            "  [[ 0.00178355  0.19194585 -0.06004953  0.1245324   0.20288545\n",
            "    -0.04758513 -0.09271508  0.07102025  0.23435676 -0.1010589\n",
            "    -0.22030932  0.2093429  -0.11074632 -0.18114245  0.00763994\n",
            "     0.21748775]\n",
            "   [ 0.17683005 -0.00260222 -0.15310723 -0.24552715 -0.07519209\n",
            "     0.02902019 -0.15512651  0.07155192 -0.12440825 -0.00612116\n",
            "    -0.01399356 -0.11836183 -0.02350152  0.04031479  0.0007174\n",
            "     0.01331902]\n",
            "   [-0.21044677 -0.02530861  0.04255468 -0.071935    0.22423601\n",
            "    -0.12318146  0.11011297 -0.19562727  0.12090373 -0.23425603\n",
            "    -0.00198889 -0.23576325 -0.01673615  0.05653775  0.05733353\n",
            "     0.03774285]\n",
            "   [ 0.19920486 -0.22386098 -0.16359824  0.07336897 -0.01593292\n",
            "     0.02662516 -0.1499722   0.0691427   0.11087829 -0.14132196\n",
            "    -0.04079366  0.15999722 -0.21737558  0.23761892  0.19051301\n",
            "    -0.1641435 ]\n",
            "   [-0.14874738  0.0058499   0.01213872 -0.11930001 -0.11980623\n",
            "     0.01169252  0.21036148  0.0697934  -0.06820589  0.13446772\n",
            "    -0.24141169  0.02393299 -0.11293584 -0.08480215  0.02182961\n",
            "     0.22851199]\n",
            "   [-0.16176802  0.14967495 -0.1534357   0.12605977 -0.14440405\n",
            "     0.17948729 -0.09405679 -0.15599376  0.2192688  -0.19885916\n",
            "    -0.16727215 -0.2150665   0.08843929  0.01606619 -0.11956054\n",
            "    -0.19678873]\n",
            "   [-0.15818846  0.17040563 -0.22329575  0.15950322 -0.08339566\n",
            "    -0.13411182 -0.22817886  0.10235798 -0.23974931  0.0520075\n",
            "     0.08387071  0.17671806 -0.06313086  0.13978595  0.06589007\n",
            "     0.12629837]\n",
            "   [-0.11749661  0.1807043   0.19513065  0.10023212  0.24173987\n",
            "    -0.23178506  0.1800754   0.0607186  -0.06471813  0.04781502\n",
            "     0.00729698  0.07480192  0.18674302  0.07724226  0.14441031\n",
            "     0.01649761]]]\n",
            "\n",
            "\n",
            " [[[-0.03311497  0.1258766  -0.03980756 -0.09861064 -0.1277082\n",
            "     0.10000879  0.11820972 -0.18009526 -0.15451479 -0.17294663\n",
            "     0.17020208 -0.04012883 -0.19905847  0.17517418  0.1074158\n",
            "     0.01770061]\n",
            "   [ 0.07383627  0.04693967  0.21433377  0.2004798   0.17673051\n",
            "     0.2450909   0.14661628  0.19307435 -0.12841845 -0.13358784\n",
            "     0.13772935 -0.13422966  0.06645954 -0.16164523  0.18756425\n",
            "     0.08142269]\n",
            "   [ 0.06395507  0.16826946  0.17796838  0.01377469 -0.09145498\n",
            "     0.10017228  0.12440956 -0.06524813  0.17235386 -0.06631768\n",
            "    -0.12142986  0.14612275 -0.04920489  0.01905     0.08849114\n",
            "     0.09312445]\n",
            "   [-0.21430194  0.14969599  0.12995493 -0.0860402  -0.15594345\n",
            "    -0.19697523 -0.05098385  0.15076458 -0.20623553  0.19102901\n",
            "    -0.05948722  0.16220903  0.0549596  -0.17324758  0.07403332\n",
            "     0.23476404]\n",
            "   [ 0.18535054 -0.01974255  0.13889718 -0.01011729 -0.24364251\n",
            "    -0.21387649 -0.2092315  -0.08070034 -0.02537143 -0.13360578\n",
            "    -0.04594654 -0.18447804  0.10211372 -0.01157206 -0.12049222\n",
            "    -0.03162944]\n",
            "   [ 0.16127586 -0.24691695  0.04138279 -0.22977823 -0.12569487\n",
            "     0.02260119  0.17128283 -0.16517222  0.0648585  -0.16704696\n",
            "     0.24355829 -0.18485177  0.2120052  -0.20207983 -0.00382847\n",
            "     0.11211783]\n",
            "   [-0.06655192  0.1841929   0.10423934 -0.18308032 -0.1908015\n",
            "    -0.24732792 -0.21727347 -0.16036326 -0.0067749  -0.15492892\n",
            "     0.01601815 -0.09391475  0.23498768 -0.09983802  0.23809403\n",
            "    -0.09367448]\n",
            "   [ 0.22278887 -0.22996378 -0.13383609  0.02667856  0.21619731\n",
            "    -0.09844011  0.04117292  0.03521949 -0.00295264 -0.06687611\n",
            "    -0.16115874 -0.24970424 -0.22584152  0.04821837 -0.02460539\n",
            "    -0.23140329]]\n",
            "\n",
            "  [[-0.18384045 -0.07131445 -0.02003753 -0.12345749 -0.24772805\n",
            "    -0.0591681  -0.22099876 -0.10867238  0.05496579 -0.24000043\n",
            "     0.12130052  0.05348402  0.17916197  0.10360909  0.15508461\n",
            "    -0.24735516]\n",
            "   [-0.08566415  0.17750949  0.11974221  0.16773748 -0.0830943\n",
            "    -0.08058    -0.00577033 -0.14643836  0.24162132 -0.05857408\n",
            "    -0.19055021  0.1345228  -0.22779644 -0.1601823  -0.16117483\n",
            "    -0.10286498]\n",
            "   [ 0.06133574  0.24821758 -0.22794688  0.02049685 -0.03034788\n",
            "     0.241229    0.10711557 -0.01992434 -0.08800435 -0.05443317\n",
            "     0.10572845  0.01207262 -0.13105512 -0.22861475  0.09859848\n",
            "     0.20748681]\n",
            "   [ 0.20250797 -0.24068254  0.11085892  0.11751884 -0.20209771\n",
            "     0.17610735  0.10797662 -0.20836651 -0.08102417 -0.07290971\n",
            "     0.03967398  0.23608232  0.10115141 -0.11907947 -0.22285402\n",
            "     0.2226901 ]\n",
            "   [-0.01933706 -0.18380052  0.16316366 -0.02370656  0.15015\n",
            "     0.06676596 -0.23134565  0.09539664  0.22972149  0.2059533\n",
            "     0.03598803  0.18620443 -0.10007733  0.18203467 -0.02344739\n",
            "     0.17151207]\n",
            "   [-0.12270039 -0.16479349 -0.00698209 -0.2356919   0.12461263\n",
            "    -0.06360525  0.20608407  0.09140432 -0.24178499  0.09802401\n",
            "    -0.00190687  0.06751549 -0.22167635 -0.17189133 -0.2290473\n",
            "     0.22376955]\n",
            "   [-0.24204212 -0.12599689  0.23177564 -0.20726854 -0.00205141\n",
            "    -0.03434849  0.18935168 -0.14828146  0.17615408  0.23537391\n",
            "    -0.01974487 -0.11459219 -0.20645076 -0.13067818 -0.19092673\n",
            "    -0.00809753]\n",
            "   [ 0.12988168 -0.02145797 -0.24288124 -0.13481694 -0.06399602\n",
            "     0.10477573  0.224729   -0.1571238  -0.1104731  -0.13970822\n",
            "     0.17865449 -0.1420008  -0.09402359 -0.13309652  0.18296456\n",
            "     0.11509913]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9R2dXslNup7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "  W1 = parameters[\"W1\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  z1 = tf.nn.conv2d(X,W1,strides = [1,1,1,1], padding = 'SAME')\n",
        "  a1 = tf.nn.relu(z1)\n",
        "  p1 = tf.nn.max_pool(a1,ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME'  )\n",
        "  z2 = tf.nn.conv2d(p1,W2,strides = [1,1,1,1], padding = 'SAME')\n",
        "  a2 = tf.nn.relu(z2)\n",
        "  p2 = tf.nn.max_pool(a2,ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME'  )\n",
        "  output = tf.contrib.layers.flatten(p2)\n",
        "  z3 = tf.contrib.layers.fully_connected(output,6,activation_fn = None)\n",
        "  return z3\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCvVS-u8YYES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(z3,Y):\n",
        "  cost = tf.nn.softmax_cross_entropy_with_logits(logits = z3, labels = Y)\n",
        "  cost = tf.reduce_mean(cost)\n",
        "  return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUam5Q0bdQNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(x_train,y_train, learning_rate = 0.01, num_epochs = 250, minibatch_size = 100, print_cost = True):\n",
        "  ops.reset_default_graph()\n",
        "  costs = []\n",
        "  tf.set_random_seed(1)\n",
        "  seed = 3\n",
        "  (m,h,w,c) = x_train.shape\n",
        "  y = y_train.shape[1]\n",
        "  X,Y = make_placeholder(h,w,c,y)\n",
        "  parameters = initialize_parameters()\n",
        "  z3 = forward_propagation(X, parameters)\n",
        "  cost = compute_cost(z3,Y)\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
        "  init = tf.global_variables_initializer()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(num_epochs):\n",
        "      minibatch_cost = 0\n",
        "      num_minibatches = int(m / minibatch_size)\n",
        "      seed=seed+1\n",
        "      rand_arrayx = np.random.rand(1080,64,64,3)\n",
        "      rand_arrayy = np.random.rand(1080,6)\n",
        "      _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:x_train, Y:y_train})\n",
        "                \n",
        "                \n",
        "      minibatch_cost += temp_cost / num_minibatches\n",
        "      if print_cost == True and epoch % 1 == 0:\n",
        "                   \n",
        "        print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
        "      if print_cost == True and epoch % 1 == 0:\n",
        "              \n",
        "        costs.append(minibatch_cost)\n",
        "          \n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per tens)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()  \n",
        "    predictions = tf.argmax(z3,1)   \n",
        "    correct_predictions = tf.equal(predictions, tf.argmax(Y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"))\n",
        "    print(accuracy)\n",
        "    train_accuracy = accuracy.eval({X:x_train, Y: y_train})\n",
        "    print(\"Train Accuracy:\", train_accuracy)\n",
        "    saver.save(sess, \"./model.ckpt\")    \n",
        "                \n",
        "    return train_accuracy, parameters    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_pe0ND6gGOs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4730
        },
        "outputId": "2de2f7cc-088f-48b3-c9fa-73b49583c2b5"
      },
      "source": [
        "print(y_train.shape)\n",
        "_, parameters = model(x_train, y_train)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 6)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-22-2d5e4d84463b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "Cost after epoch 0: 0.184140\n",
            "Cost after epoch 1: 0.179816\n",
            "Cost after epoch 2: 0.180528\n",
            "Cost after epoch 3: 0.179706\n",
            "Cost after epoch 4: 0.179102\n",
            "Cost after epoch 5: 0.178754\n",
            "Cost after epoch 6: 0.178340\n",
            "Cost after epoch 7: 0.178185\n",
            "Cost after epoch 8: 0.178145\n",
            "Cost after epoch 9: 0.177990\n",
            "Cost after epoch 10: 0.177687\n",
            "Cost after epoch 11: 0.177346\n",
            "Cost after epoch 12: 0.176902\n",
            "Cost after epoch 13: 0.176200\n",
            "Cost after epoch 14: 0.175511\n",
            "Cost after epoch 15: 0.175381\n",
            "Cost after epoch 16: 0.174413\n",
            "Cost after epoch 17: 0.173858\n",
            "Cost after epoch 18: 0.172904\n",
            "Cost after epoch 19: 0.171998\n",
            "Cost after epoch 20: 0.170786\n",
            "Cost after epoch 21: 0.170027\n",
            "Cost after epoch 22: 0.168355\n",
            "Cost after epoch 23: 0.167219\n",
            "Cost after epoch 24: 0.165344\n",
            "Cost after epoch 25: 0.163303\n",
            "Cost after epoch 26: 0.161657\n",
            "Cost after epoch 27: 0.159962\n",
            "Cost after epoch 28: 0.157571\n",
            "Cost after epoch 29: 0.155034\n",
            "Cost after epoch 30: 0.153115\n",
            "Cost after epoch 31: 0.151584\n",
            "Cost after epoch 32: 0.148280\n",
            "Cost after epoch 33: 0.145346\n",
            "Cost after epoch 34: 0.147769\n",
            "Cost after epoch 35: 0.141150\n",
            "Cost after epoch 36: 0.138555\n",
            "Cost after epoch 37: 0.137196\n",
            "Cost after epoch 38: 0.133413\n",
            "Cost after epoch 39: 0.131344\n",
            "Cost after epoch 40: 0.132464\n",
            "Cost after epoch 41: 0.126196\n",
            "Cost after epoch 42: 0.124121\n",
            "Cost after epoch 43: 0.123533\n",
            "Cost after epoch 44: 0.119170\n",
            "Cost after epoch 45: 0.116814\n",
            "Cost after epoch 46: 0.116128\n",
            "Cost after epoch 47: 0.115064\n",
            "Cost after epoch 48: 0.113145\n",
            "Cost after epoch 49: 0.121192\n",
            "Cost after epoch 50: 0.109777\n",
            "Cost after epoch 51: 0.112128\n",
            "Cost after epoch 52: 0.110362\n",
            "Cost after epoch 53: 0.107263\n",
            "Cost after epoch 54: 0.106986\n",
            "Cost after epoch 55: 0.103836\n",
            "Cost after epoch 56: 0.101938\n",
            "Cost after epoch 57: 0.106696\n",
            "Cost after epoch 58: 0.104697\n",
            "Cost after epoch 59: 0.101946\n",
            "Cost after epoch 60: 0.099524\n",
            "Cost after epoch 61: 0.100832\n",
            "Cost after epoch 62: 0.097293\n",
            "Cost after epoch 63: 0.095779\n",
            "Cost after epoch 64: 0.096853\n",
            "Cost after epoch 65: 0.092189\n",
            "Cost after epoch 66: 0.093286\n",
            "Cost after epoch 67: 0.092996\n",
            "Cost after epoch 68: 0.092557\n",
            "Cost after epoch 69: 0.088833\n",
            "Cost after epoch 70: 0.090392\n",
            "Cost after epoch 71: 0.092562\n",
            "Cost after epoch 72: 0.087312\n",
            "Cost after epoch 73: 0.088302\n",
            "Cost after epoch 74: 0.085121\n",
            "Cost after epoch 75: 0.087126\n",
            "Cost after epoch 76: 0.083249\n",
            "Cost after epoch 77: 0.084945\n",
            "Cost after epoch 78: 0.082425\n",
            "Cost after epoch 79: 0.081798\n",
            "Cost after epoch 80: 0.081552\n",
            "Cost after epoch 81: 0.078932\n",
            "Cost after epoch 82: 0.078580\n",
            "Cost after epoch 83: 0.077887\n",
            "Cost after epoch 84: 0.075848\n",
            "Cost after epoch 85: 0.076028\n",
            "Cost after epoch 86: 0.074052\n",
            "Cost after epoch 87: 0.074144\n",
            "Cost after epoch 88: 0.073953\n",
            "Cost after epoch 89: 0.073102\n",
            "Cost after epoch 90: 0.073382\n",
            "Cost after epoch 91: 0.072710\n",
            "Cost after epoch 92: 0.071695\n",
            "Cost after epoch 93: 0.070424\n",
            "Cost after epoch 94: 0.068933\n",
            "Cost after epoch 95: 0.070065\n",
            "Cost after epoch 96: 0.069926\n",
            "Cost after epoch 97: 0.070002\n",
            "Cost after epoch 98: 0.068762\n",
            "Cost after epoch 99: 0.065499\n",
            "Cost after epoch 100: 0.066784\n",
            "Cost after epoch 101: 0.066798\n",
            "Cost after epoch 102: 0.069074\n",
            "Cost after epoch 103: 0.067467\n",
            "Cost after epoch 104: 0.064174\n",
            "Cost after epoch 105: 0.064645\n",
            "Cost after epoch 106: 0.063670\n",
            "Cost after epoch 107: 0.065553\n",
            "Cost after epoch 108: 0.062723\n",
            "Cost after epoch 109: 0.061294\n",
            "Cost after epoch 110: 0.061380\n",
            "Cost after epoch 111: 0.061330\n",
            "Cost after epoch 112: 0.060446\n",
            "Cost after epoch 113: 0.058751\n",
            "Cost after epoch 114: 0.058235\n",
            "Cost after epoch 115: 0.058339\n",
            "Cost after epoch 116: 0.057418\n",
            "Cost after epoch 117: 0.056516\n",
            "Cost after epoch 118: 0.056483\n",
            "Cost after epoch 119: 0.055832\n",
            "Cost after epoch 120: 0.055362\n",
            "Cost after epoch 121: 0.054738\n",
            "Cost after epoch 122: 0.054439\n",
            "Cost after epoch 123: 0.053943\n",
            "Cost after epoch 124: 0.053306\n",
            "Cost after epoch 125: 0.053287\n",
            "Cost after epoch 126: 0.052518\n",
            "Cost after epoch 127: 0.052094\n",
            "Cost after epoch 128: 0.052026\n",
            "Cost after epoch 129: 0.051314\n",
            "Cost after epoch 130: 0.050922\n",
            "Cost after epoch 131: 0.050656\n",
            "Cost after epoch 132: 0.050197\n",
            "Cost after epoch 133: 0.049974\n",
            "Cost after epoch 134: 0.049559\n",
            "Cost after epoch 135: 0.048963\n",
            "Cost after epoch 136: 0.048696\n",
            "Cost after epoch 137: 0.048421\n",
            "Cost after epoch 138: 0.047979\n",
            "Cost after epoch 139: 0.047596\n",
            "Cost after epoch 140: 0.047193\n",
            "Cost after epoch 141: 0.046766\n",
            "Cost after epoch 142: 0.046430\n",
            "Cost after epoch 143: 0.046138\n",
            "Cost after epoch 144: 0.045822\n",
            "Cost after epoch 145: 0.045542\n",
            "Cost after epoch 146: 0.045434\n",
            "Cost after epoch 147: 0.045544\n",
            "Cost after epoch 148: 0.046036\n",
            "Cost after epoch 149: 0.046043\n",
            "Cost after epoch 150: 0.045421\n",
            "Cost after epoch 151: 0.044175\n",
            "Cost after epoch 152: 0.043743\n",
            "Cost after epoch 153: 0.044148\n",
            "Cost after epoch 154: 0.043664\n",
            "Cost after epoch 155: 0.042753\n",
            "Cost after epoch 156: 0.042159\n",
            "Cost after epoch 157: 0.042281\n",
            "Cost after epoch 158: 0.042146\n",
            "Cost after epoch 159: 0.041356\n",
            "Cost after epoch 160: 0.040772\n",
            "Cost after epoch 161: 0.040714\n",
            "Cost after epoch 162: 0.040688\n",
            "Cost after epoch 163: 0.040472\n",
            "Cost after epoch 164: 0.040020\n",
            "Cost after epoch 165: 0.039580\n",
            "Cost after epoch 166: 0.039671\n",
            "Cost after epoch 167: 0.040586\n",
            "Cost after epoch 168: 0.042752\n",
            "Cost after epoch 169: 0.046061\n",
            "Cost after epoch 170: 0.049501\n",
            "Cost after epoch 171: 0.046151\n",
            "Cost after epoch 172: 0.041034\n",
            "Cost after epoch 173: 0.040089\n",
            "Cost after epoch 174: 0.043074\n",
            "Cost after epoch 175: 0.042207\n",
            "Cost after epoch 176: 0.038135\n",
            "Cost after epoch 177: 0.042194\n",
            "Cost after epoch 178: 0.042211\n",
            "Cost after epoch 179: 0.037282\n",
            "Cost after epoch 180: 0.043519\n",
            "Cost after epoch 181: 0.039184\n",
            "Cost after epoch 182: 0.038949\n",
            "Cost after epoch 183: 0.040156\n",
            "Cost after epoch 184: 0.035778\n",
            "Cost after epoch 185: 0.038614\n",
            "Cost after epoch 186: 0.035806\n",
            "Cost after epoch 187: 0.037412\n",
            "Cost after epoch 188: 0.036061\n",
            "Cost after epoch 189: 0.036653\n",
            "Cost after epoch 190: 0.035735\n",
            "Cost after epoch 191: 0.035210\n",
            "Cost after epoch 192: 0.035264\n",
            "Cost after epoch 193: 0.034778\n",
            "Cost after epoch 194: 0.034808\n",
            "Cost after epoch 195: 0.033852\n",
            "Cost after epoch 196: 0.034557\n",
            "Cost after epoch 197: 0.033275\n",
            "Cost after epoch 198: 0.034008\n",
            "Cost after epoch 199: 0.032902\n",
            "Cost after epoch 200: 0.033392\n",
            "Cost after epoch 201: 0.032692\n",
            "Cost after epoch 202: 0.032720\n",
            "Cost after epoch 203: 0.032542\n",
            "Cost after epoch 204: 0.032101\n",
            "Cost after epoch 205: 0.032341\n",
            "Cost after epoch 206: 0.031716\n",
            "Cost after epoch 207: 0.031913\n",
            "Cost after epoch 208: 0.031397\n",
            "Cost after epoch 209: 0.031492\n",
            "Cost after epoch 210: 0.031173\n",
            "Cost after epoch 211: 0.031062\n",
            "Cost after epoch 212: 0.030895\n",
            "Cost after epoch 213: 0.030635\n",
            "Cost after epoch 214: 0.030602\n",
            "Cost after epoch 215: 0.030288\n",
            "Cost after epoch 216: 0.030307\n",
            "Cost after epoch 217: 0.030024\n",
            "Cost after epoch 218: 0.029921\n",
            "Cost after epoch 219: 0.029776\n",
            "Cost after epoch 220: 0.029555\n",
            "Cost after epoch 221: 0.029486\n",
            "Cost after epoch 222: 0.029257\n",
            "Cost after epoch 223: 0.029166\n",
            "Cost after epoch 224: 0.029000\n",
            "Cost after epoch 225: 0.028853\n",
            "Cost after epoch 226: 0.028749\n",
            "Cost after epoch 227: 0.028589\n",
            "Cost after epoch 228: 0.028500\n",
            "Cost after epoch 229: 0.028370\n",
            "Cost after epoch 230: 0.028299\n",
            "Cost after epoch 231: 0.028271\n",
            "Cost after epoch 232: 0.028392\n",
            "Cost after epoch 233: 0.028701\n",
            "Cost after epoch 234: 0.029614\n",
            "Cost after epoch 235: 0.030855\n",
            "Cost after epoch 236: 0.033723\n",
            "Cost after epoch 237: 0.033715\n",
            "Cost after epoch 238: 0.032772\n",
            "Cost after epoch 239: 0.029095\n",
            "Cost after epoch 240: 0.027209\n",
            "Cost after epoch 241: 0.028441\n",
            "Cost after epoch 242: 0.029844\n",
            "Cost after epoch 243: 0.029257\n",
            "Cost after epoch 244: 0.027481\n",
            "Cost after epoch 245: 0.027001\n",
            "Cost after epoch 246: 0.027885\n",
            "Cost after epoch 247: 0.027976\n",
            "Cost after epoch 248: 0.027231\n",
            "Cost after epoch 249: 0.026514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFs455xrlycI551yjPFk455xr1P8Hi7naKNVpfyIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
            "Train Accuracy: 0.9203704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P77QvvLwtVR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "permutationy = list(np.random.permutation(6))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYtQTEoYkiif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgOSVYIg3Uv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f2fa7324-c14c-41eb-a745-6fec8fbd5192"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ea90a93df8ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EauEkF-23gao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}